"""Code for the experiment to determine appropriate dataset sizes when using this framework
"""
#%% Initialise
import os
import pathlib
import sys

import numpy as np
import pandas as pd
from joblib import load

# local imports
module_dir = os.path.dirname(os.path.abspath(__file__))

sys.path.append(os.path.abspath(os.path.join(module_dir, "..")))
#from notebooksupport import calculate_distances
from phaser.evaluation import ComputeMetrics, MetricMaker
from phaser.utils import load_labelencoders

DISTANCE_METRICS = {
    "Hamming": "hamming"
}

hash_directory = r"."
output_directory_base = os.path.abspath(os.path.join(module_dir, "sample_data"))
label_filename = os.path.abspath(os.path.join(module_dir, "LabelEncoders"))

sample_sizes = [1000, 10_000, 100_000, 999_000] # sample test size
iterations = 1000 # number of times to generate distances for each sample size



# Load the label encoders
le = load_labelencoders(filename=label_filename, path=hash_directory)

# Get values to construct triplets
TRANSFORMS = le["t"].classes_
METRICS = le["m"].classes_
ALGORITHMS = le["a"].classes_

print(", ".join(TRANSFORMS))
print(", ".join(METRICS))
print(", ".join(ALGORITHMS))

#%% Process Samples

hash_path = os.path.join(module_dir, hash_directory, "hashes.csv.bz2")
df_h = pd.read_csv(hash_path)
aggregate = pd.DataFrame()

# Generate triplet combinations without 'orig'
triplets = np.array(
    np.meshgrid(ALGORITHMS, [t for t in TRANSFORMS if t != "orig"], DISTANCE_METRICS)
).T.reshape(-1, 3)

for s in sample_sizes:
    print(f"Working on sample size of {s}")
    for i in range(0, iterations):
        if i % 100 == 0:
             print(f"Iteration: {i}")

        #Load hashes and labels from the output generated by the previous step and calculate inter- and intra-distances.
        df_d = calculate_distances(hash_directory=hash_directory, distance_metrics=DISTANCE_METRICS, progress_report=False, out_dir="", sample_files=s,save_to_disk=False)
        
        cm = ComputeMetrics(le, df_d, df_h, analyse_bits=False)
        metrics, bitfreq = cm.fit(triplets=triplets, weighted=False)
        metrics["sample_size"] = s
        metrics["iteration"] = i
        aggregate = pd.concat([aggregate, metrics])

aggregate.to_csv(os.path.join(hash_directory, "aggregate.csv.bz2"), index=False)

# %% Visualise
from seaborn import scatterplot, jointplot, barplot, boxplot, violinplot
import matplotlib.pyplot as plt
import itertools


#print(aggregate.head())
if not'aggregate' in locals():
    aggregate = pd.read_csv(os.path.join(hash_directory, "aggregate.csv.bz2"))

#print(aggregate.head())

# for a in ALGORITHMS:
#     print(a)
#     #for t in TRANSFORMS:
#     #print(a,t)
#     #data = aggregate.loc[aggregate["Transform"] == t]
#     data = aggregate[aggregate["Algorithm"] == a]
#     origvals = data[data["Transform"] == "orig"].index
#     data.drop(origvals, inplace=True)
#     #print(data.head())
#     fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(8,5), constrained_layout=True)
#     ax_ = scatterplot(data=data, x="sample_size", y="Threshold" , hue="Transform", ax=ax)

#     plt.show()
        

METRICS = ["fprate", "fnrate", "Threshold"]

n_cols = len(METRICS)
n_rows = len(ALGORITHMS)
# Subset data
fig, axes = plt.subplots(ncols=n_cols, nrows=n_rows, figsize=(15,8), constrained_layout=True, 
                            sharex=True, sharey=False)

mks = itertools.cycle(['o', 'x', '+', '^', '*', '8', 's', 'p', 'D', 'V'])
markers = [next(mks) for i in TRANSFORMS]

for col_i, metric in enumerate(METRICS):
    for row_i, algo in enumerate(ALGORITHMS):
            # Transform strings to labels
            data = aggregate[aggregate["Algorithm"] == algo].copy()
            origvals = data[data["Transform"] == "orig"].index
            #water = data[data["Transform"] == "Flip_Horizontal"].index
            data["total"] = data["FP"] + data["FN"] + data["TP"] + data["TN"]
            data["fprate"]  = data["FP"] /  data["total"]
            data["fnrate"]  = data["FN"] /  data["total"]
            data.drop(origvals, inplace=True)
            #data.drop(water, inplace=True)
            ax_ = boxplot(data=data, x="sample_size", y=metric, hue="Transform", ax=axes[row_i, col_i])#, alpha=.30)
        
            #ax_ = barplot(data=data, x="sample_size", y="Threshold" , ax=axes[row_i, col_i], legend=False)
            #ax_.get_legend().remove()
            ax_.set_title(f"{algo}-{metric}")
ax_.legend()
plt.show()




# data = aggregate.loc[aggregate["Transform"] == "Watermark"]
# data = data.loc[data["sample_size"] <20_000]
# data = data.loc[data["Algorithm"] == "Wavehash"]
# print(data.head())
# #data = aggregate.query("Algorithm == PDQ, Transform == Watermark").copy()

# ax = jointplot(data=data, x="sample_size", y="AUC")# , hue="time", style="time")
# #ax.set_ylim(0.0,1.0)
# plt.show()

# ax = jointplot(data=data, x="sample_size", y="Threshold")# , hue="time", style="time")
# #ax.set_ylim(0.0,1.0)
# plt.show()

# data = aggregate.loc[aggregate["Transform"] == "Flip_Horizontal"]
# data = data.loc[data["sample_size"] <20_000]
# data = data.loc[data["Algorithm"] == "Wavehash"]
# print(data.head())
# ax = jointplot(data=data, x="sample_size", y="AUC")# , hue="time", style="time")
# #ax.set_ylim(0.0,1.0)
# plt.show()

# ax = jointplot(data=data, x="sample_size", y="Threshold")# , hue="time", style="time")
# #ax.set_ylim(0.0,1.0)
# plt.show()
