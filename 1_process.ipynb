{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Pre-requisite Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Available Modules\n",
    "Run the Cell below to list the names of the available:\n",
    "- Perceptual Hashing Algorithms\n",
    "- Transformers\n",
    "- Similarity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooksupport import list_modular_components\n",
    "\n",
    "nl = '\\n'\n",
    "for module_name, functions in list_modular_components().items():\n",
    "    print( f\"{module_name}:{nl}{nl.join(functions)}\")\n",
    "    print(nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Transforms\n",
    "- Test out transforms and their parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phaser.transformers import *\n",
    "from phaser.utils import ImageLoader\n",
    "\n",
    "# list of functions and parameters to create transform classes\n",
    "# Edit these to change output.\n",
    "transforms = [\n",
    "    Border(border_colour=(255,0,0), border_width=30),\n",
    "    Crop(cropbox_absolute=[20,20,0,0]),\n",
    "    Enhance(sharpnessfactor=0.0, contrastfactor=2, colourfactor=0.3, brightnessfactor=0.7),\n",
    "    Flip(direction='Horizontal'),\n",
    "    Rescale(scalefactor=2.1, thumbnail_aspect=False),\n",
    "    Rescale(fixed_dimensions=(200,200), thumbnail_aspect=True),\n",
    "    Rotate(degrees_counter_clockwise=10),\n",
    "    Rotate(degrees_counter_clockwise=-20),\n",
    "    Watermark()\n",
    "]\n",
    "\n",
    "# Load an image to transform\n",
    "im = ImageLoader(f\"images/972381743_5677b420ab.jpg\")\n",
    "\n",
    "# Apply each specified transform to the image and save to \"test/\"\n",
    "for t in transforms:\n",
    "    modified = t.fit(im) # fit function applies the transform\n",
    "    filepath = t.saveToDisk(image=modified, save_directory=\"test\", filename=im.filename )\n",
    "    print(filepath)\n",
    "    display(modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Experimental Conditions\n",
    "- Specify path to original (unmodified) images. Transforms will be applied to these, and these serve as the ground truth for intra-distance analysis.\n",
    "- Specify output directory\n",
    "- Specify dictionary of Perceptual Hashes to use (with parameters)\n",
    "    - Format: ```<name_string>: <class_name>(<arguments>)```\n",
    "    - Must be imported in this cell, base algorithms defined in ```phaser.hashing._algorithms.py```.\n",
    "    - Class should extend ```phaser.hashing._algorithms.PerceptalHash```\n",
    "- Specify Transforms to use.\n",
    "    - Format: ```<clas_name>(<arguments>)```\n",
    "    - Must be imported in this cell, base algorithms defined in ```phaser.transformers._transforms.py```.\n",
    "    - Use ```TransformFromDisk``` and specify a path as the argument if the transform files already exist on disk (must have same name as originals to match)\n",
    "- Specify Distance metrics to use.\n",
    "    - Format: Dictionary with ```<Human Readable Name>:<metric>``` (metric should be str or Callable, see below)\n",
    "    - If the distance metric is part of ```scipy.spatial.distance```, specify the name as a ```str```\n",
    "    - If a custom distance metric is provided in ```phaser.similarities._distances.py```, import and pass the ```function reference```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics look valid!\n"
     ]
    }
   ],
   "source": [
    "# Specify path of the original (non-transformed) dataset\n",
    "# e.g. \"F:\\Datasets\\images\"\n",
    "original_path = r\"images\"\n",
    "\n",
    "# Specify output directory\n",
    "output_directory = r\"./demo_outputs\"\n",
    "\n",
    "# Specify Perceptual Hashing Algorithms\n",
    "\n",
    "from phaser.hashing import *\n",
    "ALGORITHMS = {\n",
    "        'pHash': PHash(hash_size=8, highfreq_factor=4),\n",
    "        \"PDQ\": PdqHash(),\n",
    "        \"Wavehash\": WaveHash()\n",
    "        #'Colourhash': ColourHash()\n",
    "        }\n",
    "\n",
    "# Specify Transforms functions \n",
    "from phaser.transformers import *\n",
    "TRANSFORMERS = [\n",
    "    # Border(border_color=(255,0,0), border_width=30, saveToPath=''),\n",
    "    Flip(direction='Horizontal'),\n",
    "    Crop(cropbox_absolute=[10,10,10,10]),\n",
    "    Border(border_colour=(255,255,255), border_width=30),\n",
    "    Watermark(),\n",
    "    # TransformFromDisk(r\"F:/testmods/Border30black\"),\n",
    "    # TransformFromDisk(r\"F:/testmods/Crop5pc\"),\n",
    "    # TransformFromDisk(r\"F:/testmods/Mirrorx\"),\n",
    "    # TransformFromDisk(r\"F:/testmods/Watermark/\")\n",
    "\n",
    "    ]\n",
    "\n",
    "from phaser.similarities import *\n",
    "DISTANCE_METRICS = {\n",
    "    \"Hamming\": \"hamming\",\n",
    "    \"Cosine\": \"cosine\",\n",
    "    # \"Test_Synthetic\": test_synthetic\n",
    "}\n",
    "\n",
    "# === EDIT ABOVE LINE ======================\n",
    "\n",
    "# Test that metrics have been entered correctly\n",
    "from phaser.similarities import validate_metrics\n",
    "if validate_metrics(DISTANCE_METRICS):\n",
    "    print(\"Metrics look valid!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Files\n",
    "\n",
    "- Hash original files with each algorithm\n",
    "- Generate and hash transform files\n",
    "- Output hashes to CSV files compressed to .bz (bzip) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images in c:\\Users\\Sean\\Documents\\GitHub\\test_lib\\images.\n",
      "Creating output directory at c:\\Users\\Sean\\Documents\\GitHub\\test_lib\\demo_outputs...\n",
      "Doing hashing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787398c5da9f4e8c842beaa2920a6c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving hashes.csv and labels for filenames (f), algorithms (a) and transforms (t) to bzip files..\n"
     ]
    }
   ],
   "source": [
    "from notebooksupport import do_hashing\n",
    "\n",
    "# Pass the settings through to a helper function which does the hashing and applies transforms\n",
    "do_hashing(originals_path=original_path, algorithms=ALGORITHMS, transformers=TRANSFORMERS, output_directory=output_directory, n_jobs=-1, progress_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Similarity Scores\n",
    "There are two types of score calculated here:\n",
    "- Intra-score: Where the original images are compared to their modifications. This is a 1-to-1 mapping (N * #hashes * #transforms * #comparison_metrics)\n",
    "    - This is used to determine how robust the hash and comparison metric are to each transform class.\n",
    "    - Ideally original images should have a distance of 0 (simlartiy of 1) to their transforms.\n",
    "- Inter-score: Where images within a given tranform (or originals) are compared to themselves for each given comparison metric. Inter-scores are sampled to match the size of the intra-score class. (Calculating all pairwise combinations generates many more samples, (N*N-1/2)\n",
    "    - This gives us a baseline behaviour, with the assumption that the images should *not* match.\n",
    "    - On aggregate, random unrelated images should be about 0.5 different, as this makes the best use of the metric space.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded from c:\\Users\\Sean\\Documents\\GitHub\\test_lib\\demo_outputs\\hashes.csv.bz2\n",
      "Algorithms: \t Colourhash, pHash\n",
      "Transforms: \t Border_bw30_bc255.0.0, Flip_Horizontal, Waternmark, orig\n",
      "Metrics: \t Cosine, Hamming\n",
      "Saving metric encoder to le_m.\n",
      "\n",
      "Computing Intra-distances...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c076b2f910b34cb98cd696d4115dfd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d158807f072e4915b730bbabdee5d9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Metric:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2ef92557324f61a65b49f88515be0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Metric:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total intra-image comparisons = 80\n",
      "\n",
      "Computing Inter-distance with 7 samples per image...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f069ef5b4e60429c942e0a2901e6b109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Algorithm:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9624e9350dbf4113aebb80dbbe1b9284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Metric:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66e6ee001a84bd2b3d72a480b16960a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Metric:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairwise comparisons per triplet (algo., trans., metric) = 21\n",
      "Total number of inter-distance observations = 84\n",
      "Saving distance scores to c:\\Users\\Sean\\Documents\\GitHub\\test_lib\\demo_outputs\\distances.csv.bz2.\n"
     ]
    }
   ],
   "source": [
    "from notebooksupport import calculate_distances\n",
    "\n",
    "# Load hashes and labels from the output generated by the previous step and calculate inter- and intra-distances.\n",
    "calculate_distances(hash_directory=output_directory, distance_metrics=DISTANCE_METRICS, progress_report=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_lib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
